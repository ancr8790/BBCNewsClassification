{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Week 4 Mini Project BBC News Classification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Description of kaggle competition for BBC News Classification)\n",
    "\n",
    "Text documents are one of the richest sources of data for businesses.\n",
    "\n",
    "We’ll use a public dataset from the BBC comprised of 2225 articles, each labeled under one of 5 categories: business, entertainment, politics, sport or tech.\n",
    "\n",
    "The dataset is broken into 1490 records for training and 735 for testing. The goal will be to build a system that can accurately classify previously unseen news articles into the right category.\n",
    "\n",
    "The competition is evaluated using Accuracy as a metric.\n",
    "\n",
    "Following blog has good information on how to look at the problem. https://cloud.google.com/blog/products/gcp/problem-solving-with-ml-automatic-document-classification\n",
    "\n",
    "## Evaluation for submission to Kaggle\n",
    "The evaluation metric for this competition is Accuracy. Sample Solution FIle shows the format required for submission. The file should contain a header and have the following two columns ArticleId (from Test File) Category (one of the five categories - sport, tech, business, entertainment or politics)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Week 4 mini project instructions\n",
    "\n",
    "### Step 1\n",
    "Extracting word features and show Exploratory Data Analysis (EDA) — Inspect, Visualize and Clean the Data (15 pts)\n",
    "\n",
    "Show a few visualizations like histograms. Describe any data cleaning procedures. Based on your EDA, what is your plan of analysis? \n",
    "\n",
    "Please feel free to look at online resources on processing raw texts to feature vectors. Many methods process texts to matrix form (word embedding), including TF-IDF, GloVe, Word2Vec, etc. Pick a method and process the raw texts to word embedding. Briefly explain the method(s) and how they work in your own words. Also, do exploratory data analysis such as word statistics and/or visualization.\n",
    "\n",
    "As we did not learn natural language processing (NLP) specific techniques such as word embeddings in the lectures, we recommend reading discussions and example codes from others in the Kaggle and/or doing some research online to make sure you understand. You can refer to any resource as needed, but make sure you “demonstrate” your understanding- please include explaining in your own words, discussions, and your interpretation. Also importantly, please have a reference list at the end of the report. \n",
    "\n",
    "### Step 2\n",
    "Building and training models. [35 pts]\n",
    "\n",
    "\n",
    "In the Kaggle competition, the training data has labels (category). Thus, it can be solved using supervised learning. In general, the more labeled data we have, the more accurate the supervised learning model will be. But unsupervised learning can be powerful even when there is a small number of labels or no labels. This assignment will apply an unsupervised approach, especially the matrix factorization method, to discover topics in the news articles and use the labels to check the accuracy.\n",
    "\n",
    "Here are some steps to guide this section: \n",
    "1) Think about this and answer: when you train the unsupervised model for matrix factorization, should you include texts (word features) from the test dataset or not as the input matrix? Why or why not?\n",
    "2) Build a model using the matrix factorization method(s) and predict the train and test data labels. Choose any hyperparameter (e.g., number of word features) to begin with.\n",
    "3) Measure the performances on predictions from both train and test datasets. You can use accuracy, confusion matrix, etc., to inspect the performance. You can get accuracy for the test data by submitting the result to Kaggle. \n",
    "4) Change hyperparameter(s) and record the results. We recommend including a summary table and/or graphs.\n",
    "5) Improve the model performance if you can- some ideas may include but are not limited to; using different feature extraction methods, fit models in different subsets of data, ensemble the model prediction results, etc. \n",
    "\n",
    "### Step 3\n",
    "Compare with supervised learning [30 pts]\n",
    "\n",
    "Use the following steps to guide your work:\n",
    "\n",
    "1) Pick and train a supervised learning method(s) and compare the results (train and test performance)\n",
    "2) Discuss comparison with the unsupervised approach. You may try changing the train data size (e.g., Include only 10%, 20%, 50% of labels, and observe train/test performance changes). Which methods are data-efficient (require a smaller amount of data to achieve similar results)? What about overfitting?\n",
    "\n",
    "\n",
    "## Part 2\n",
    "Limitation(s) of sklearn’s non-negative matrix factorization library. [20 pts]\n",
    "\n",
    "1. Load the movie ratings data (as in the HW3-recommender-system) and use matrix factorization technique(s) and predict the missing ratings from the test data. Measure the RMSE. You should use sklearn library. [10 pts]\n",
    "\n",
    "\n",
    "2. Discuss the results and why sklearn's non-negative matrix facorization library did not work well compared to simple baseline or similarity-based methods we’ve done in Module 3. Can you suggest a way(s) to fix it? [10 pts]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importing Required Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# importing all the required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "\n",
    "import re\n",
    "import itertools as it\n",
    "\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "import nltk.corpus\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import digits\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import ParameterGrid, train_test_split\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "os.getcwd()\n",
    "#os.chdir(\"C:/Users/andreacruz/Documents/University of Colorado, Boulder MSDS/Machine Learning/Unsupervised Learning/Week 4\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Loading\n",
    "\n",
    "Let's load the data and take a look at the structure of the training and test datasets..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#Import data from csv file\n",
    "BBC_train = pd.read_csv('BBC News Train.csv')\n",
    "BBC_test = pd.read_csv('BBC News Test.csv')\n",
    "\n",
    "#verify upload\n",
    "print(BBC_train.head(10))\n",
    "print(BBC_test.head(10))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   ArticleId                                               Text       Category\n",
      "0       1833  worldcom ex-boss launches defence lawyers defe...       business\n",
      "1        154  german business confidence slides german busin...       business\n",
      "2       1101  bbc poll indicates economic gloom citizens in ...       business\n",
      "3       1976  lifestyle  governs mobile choice  faster  bett...           tech\n",
      "4        917  enron bosses in $168m payout eighteen former e...       business\n",
      "5       1582  howard  truanted to play snooker  conservative...       politics\n",
      "6        651  wales silent on grand slam talk rhys williams ...          sport\n",
      "7       1797  french honour for director parker british film...  entertainment\n",
      "8       2034  car giant hit by mercedes slump a slump in pro...       business\n",
      "9       1866  fockers fuel festive film chart comedy meet th...  entertainment\n",
      "   ArticleId                                               Text\n",
      "0       1018  qpr keeper day heads for preston queens park r...\n",
      "1       1319  software watching while you work software that...\n",
      "2       1138  d arcy injury adds to ireland woe gordon d arc...\n",
      "3        459  india s reliance family feud heats up the ongo...\n",
      "4       1020  boro suffer morrison injury blow middlesbrough...\n",
      "5         51  lewsey puzzle over disallowed try england s jo...\n",
      "6       2025  blair blasts tory spending plans tony blair ha...\n",
      "7       1479  former ni minister scott dies former northern ...\n",
      "8         27  career honour for actor dicaprio actor leonard...\n",
      "9        397  tsunami  to hit sri lanka banks  sri lanka s b...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#determine how much Training data we are dealing with\n",
    "print(\"Shape of training dataframe is\", BBC_train.shape)\n",
    "print(\"Shape of testing dataframe is\", BBC_test.shape)\n",
    "print(\"Unique values of 'Category':\",pd.unique(BBC_train.Category))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#check data for N/A values\n",
    "print(BBC_train.isnull().sum(),BBC_test.isnull().sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#look at stats of dataframe\n",
    "print(BBC_train.describe())\n",
    "print(BBC_train.info())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data shapes and categories coincide with expectations. There are no null values luckily so no need to figure out how to deal with them.\n",
    "\n",
    "The Training dataset has the following attributes:\n",
    "- ArticleID: unique identifier for each article\n",
    "- Text: Body text of article\n",
    "- Category: category assigned to the article\n",
    "\n",
    "The Test dataset has the following attributes:\n",
    "- ArticleID: unique identifier for each article\n",
    "- Text: Body text of article\n",
    "\n",
    "We will need to predict the 'Category' of the Test dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Let's first take a look at the distribution of the article categories in the training dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#see distribution of article categories\n",
    "BBC_train_cat = BBC_train['Category'].value_counts()\n",
    "dist_pie = BBC_train_cat.plot(kind = 'pie',figsize = (13,13),title = \"Distribution of Article Categories\", \n",
    "    autopct='%.1f%%', subplots = 'True',fontsize = 48)\n",
    "#plt.savefig('Distribution_valid_fraud_ccc.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It looks like this training set is pretty well balanced and will perform well for model training. Next let's preview the text formats to understand what we are dealing with."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#preview text formats\n",
    "print(BBC_train.Text[5])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on this preview, there is some cleaning up to do of the dataset to provide the model with insightful training instances. Clean up will include removing punctuation, numbers, stop words, and extra spaces. Stop words are common English words that don't neccessarily provide any insightful information towards the category of the article such as \"I\", \"the\", \"and\", etc."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#lets remove punctuation, numbers, stop words, extra spaces\n",
    "def cleanup_text(dataframe, text_col):\n",
    "    #remove punctuation\n",
    "    dataframe['clean_text'] = dataframe[text_col].apply(lambda item: re.sub(r'[^\\w\\s]+', '',item))\n",
    "    #remove numbers\n",
    "    dataframe['clean_text'] = dataframe['clean_text'].apply(lambda item: re.sub(r'[0-9]+', '',item))\n",
    "    #remove stop words\n",
    "    stop_words = stopwords.words('english')\n",
    "    dataframe['clean_text'] = dataframe['clean_text'].apply(lambda item: \" \".join([x for x in item.split() if x not in stop_words]))\n",
    "    #remove extra spaces\n",
    "    dataframe['clean_text'] = dataframe['clean_text'].apply(lambda item: re.sub(' +', ' ', item))\n",
    "\n",
    "    return dataframe\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#verify cleanup applied\n",
    "BBC_train = cleanup_text(BBC_train, 'Text')\n",
    "print(BBC_train.clean_text[5])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "howard truanted play snooker conservative leader michael howard admitted used play truant spend time school friends snooker hall mr howard said time jack snooker hall llanelli done lasting damage told times educational supplement truancy bad said firm action needed mr howard also called return olevels classroom discipline mr howard eventually left llanelli grammar school snooker hall go cambridge university said think done lasting damage made snooker world champion might occasions left early afternoon honest think truancy bad thing firm action taken deal another player failed win snooker world championship jimmy whirlwind white previously admitted missing lessons instead spending days smoky halls tony meo another player used spend spare time mr white said loved game atmosphere school went window went started taking time mr howard fellow welshman ray reardon known fellow professionals dracula snooker world championship six times left school work miner terry griffiths like mr howard llanelli tournament known whether two ever clashed cues jack\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also tokenize the text which will reduce the long string of words per article into a list of words. This can help with visualizations and determine frequency of words. Lemmatizing the data can also be useful to help the model with training by reducing words to their root words while maintaining generalized meaning."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#now lets tokenize and lemmatizer\n",
    "lemm = WordNetLemmatizer()\n",
    "\n",
    "def lemmenatize(text):\n",
    "    lem = [lemm.lemmatize(item) for item in text] \n",
    "    return lem\n",
    "\n",
    "def tokenize_lemmenatize(dataframe, text_col):\n",
    "    #tokenize\n",
    "    dataframe['tockenize'] = dataframe.apply(lambda row: nltk.word_tokenize(row[text_col]), axis=1)\n",
    "    #lemmatize\n",
    "    dataframe['lemmatize'] = dataframe['tockenize'].apply(lambda item: lemmenatize(item))\n",
    "    #sort alphabetically\n",
    "    dataframe['lemmatize'] = dataframe['lemmatize'].apply(lambda item: sorted(item))\n",
    "    #count number of words in string\n",
    "    dataframe['num_words'] = dataframe['lemmatize'].apply(lambda strings: len(strings))\n",
    "\n",
    "    return dataframe"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#verify tockenize & lemmenatize \n",
    "BBC_train = tokenize_lemmenatize(BBC_train, 'clean_text')\n",
    "print(BBC_train['lemmatize'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0       [accounting, accounting, accounting, accountin...\n",
      "1       [activity, analyst, bank, bank, bernd, busines...\n",
      "2       [absorbed, across, ago, almost, also, also, al...\n",
      "3       [able, across, activity, advisor, ageing, ago,...\n",
      "4       [action, action, added, adding, admit, ago, ag...\n",
      "                              ...                        \n",
      "1485    [actor, actress, afterwards, although, announc...\n",
      "1486    [act, act, add, adding, addition, advantage, a...\n",
      "1487    [added, adding, adding, aimed, also, also, bac...\n",
      "1488    [according, according, according, added, added...\n",
      "1489    [across, address, affected, announcing, appear...\n",
      "Name: lemmatize, Length: 1490, dtype: object\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#plot distribution of word count per article\n",
    "fig, ax = plt.subplots(figsize =(10, 10))\n",
    "n_bins = 25\n",
    "ax.hist(BBC_train.num_words, bins = n_bins)\n",
    "\n",
    "plt.xlabel(\"Word Count\")\n",
    "plt.ylabel(\"Article Count\")\n",
    "plt.title('Distribution of Word Count per Article in Training Dataset')\n",
    "\n",
    "plt.show()\n",
    "#couple of outliers that may want to be removed so as not to skew model building moving forward (>600?)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#remove outliers from training dataset\n",
    "print(round((len(BBC_train[BBC_train['num_words'] > 600])/len(BBC_train))*100,2),'% of dataset have > 600 word counts per article')\n",
    "print(\"length of full dataset\",len(BBC_train))\n",
    "BBC_train = BBC_train[BBC_train['num_words'] < 600]\n",
    "#confirm outliers were dropped\n",
    "print(\"length of reduced dataset\",len(BBC_train))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.74 % of dataset have > 600 word counts per article\n",
      "length of full dataset 1490\n",
      "length of reduced dataset 1479\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#show boxplot of words per article in each category\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.boxplot(data=BBC_train, x='Category', y='num_words')\n",
    "plt.ylabel('Number of Words/article')\n",
    "plt.title('Box plot of Training Data')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on the exploratory data analysis, I decided to remove articles that had less than 600 words per article to prevent overfitting for future model training. Given that there is a relatively equal distribution of each category in the training dataset, it is well set up for a supervised model implementation. However, for the purpose of this exercise we want to take an unsupervised learning approach. We will vectorize the data from words to numbers so they are suitable for matrices and then use that transformation to train a non-negative matrix factorization model. This will then be optimized, run on the test data, and subsequently be submitted to the kaggle competition."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Unsupervised Model training and building"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, we will implement some helper functions to helps us predict the category of the article by grabbing the index of the maximum values along each row."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "#function to predict category of article based on transformed data (NMFmatrix) which is scaled by n_featrues\n",
    "def predict(NMFmatrix):\n",
    "    indices_of_max_values = np.argmax(NMFmatrix, axis=1)\n",
    "    return indices_of_max_values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Additionally, we will implement a Label permutation function that was adapted from my implementation in this course's week 2 lab on clustering. This function tests out all the possible permutations of the label maping as a combo of numbers ranging from 0-4 and testing which permuation gives the highest accuracy based on the assignements in the training data. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def label_permute_compare(ytdf,yp, n = 5):\n",
    "    \"\"\"\n",
    "    ytdf: Training data\n",
    "    yp: clustering label prediction output\n",
    "    Returns best permuted label order and accuracy. \n",
    "    Example output: (3, 4, 1, 2, 0), 0.88 \n",
    "    \"\"\"\n",
    "# your code here\n",
    "\n",
    "    perm = list(it.permutations(range(0,n),n))\n",
    "    ytdf_lab = ['business', 'tech', 'politics', 'sport', 'entertainment']\n",
    "    #print(ytdf_lab)\n",
    "\n",
    "    best_perm = []\n",
    "    score = 0\n",
    "    for i in perm:\n",
    "        dict = {}\n",
    "        for j in range(len(i)):\n",
    "            dict[ytdf_lab[j]] = i[j]\n",
    "        #print(dict)\n",
    "\n",
    "        testing = pd.DataFrame(ytdf['Category']).replace(dict)\n",
    "\n",
    "        curr_acc = accuracy_score(testing,yp)\n",
    "        if curr_acc > score:\n",
    "            score = curr_acc\n",
    "            best_perm = i\n",
    "\n",
    "\n",
    "    return(best_perm, score)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will test out 2 different vectorizers:\n",
    "- TfidVectorizer which converts a collection of raw documents to a matrix of TF-IDF features. TF-IDF means term-frequency (the number of times a term occurs in a given document) times inverse document-frequency\n",
    "- CountVectorizer converts a collection of raw documents into a matrix that implements tokenization and occurrence counting.\n",
    "\n",
    "Both these vectorizers will be implemented into the NMF model and tested for accuracy against the training category attribute. During this training, I decided not to use texts from the test dataset to avoid overfitting and properly evaluate the model's ability to predict when shown completely new, unseen data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "#vectorizer\n",
    "#decided to train with only words in training dataset to avoid overfitting\n",
    "tfv = TfidfVectorizer(min_df = 0, max_df = 0.85, norm = 'l2', stop_words = 'english')\n",
    "tfv_train = tfv.fit_transform(BBC_train['clean_text'])\n",
    "\n",
    "cv = CountVectorizer(min_df = 0, max_df = 0.85, stop_words = 'english')\n",
    "cv_train= cv.fit_transform(BBC_train['clean_text'])\n",
    "\n",
    "#model\n",
    "nmf_model = NMF(n_components = 5, init = 'nndsvd', solver = 'cd',beta_loss = 'frobenius', l1_ratio = 0.5)\n",
    "nmf_model.fit(tfv_train)\n",
    "\n",
    "y_train = predict(nmf_model.transform(tfv_train))\n",
    "label_order, acc =  label_permute_compare(BBC_train,y_train)\n",
    "print('accuracy =', acc, \"\\nlabel_order\", label_order)\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy = 0.9168356997971603 \n",
      "label_order (4, 2, 1, 0, 3)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "#testing CV vectorizer & tuning hyper parameters\n",
    "nmf_cv_mod = NMF(n_components = 5, \n",
    "                init = 'nndsvd', \n",
    "                solver = 'cd',\n",
    "                beta_loss = 'frobenius', \n",
    "                l1_ratio = 0.5)\n",
    "nmf_cv_mod.fit(cv_train)\n",
    "\n",
    "y_train = predict(nmf_cv_mod.transform(cv_train))\n",
    "cv_label_order, cv_acc =  label_permute_compare(BBC_train,y_train)\n",
    "print('accuracy =', cv_acc, \"\\nlabel_order\", cv_label_order)\n",
    "#able to get to reasonable accuracy But takes longer"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy = 0.7200811359026369 \n",
      "label_order (0, 3, 1, 4, 2)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Based on the base hyperparameters set, the TfidfVectorizer outperforms the countvectorizer, at 91.2% vs 72% accuracy. Albeit, it takes a bit longer at 2.4 seconds vs 1.4. With additional optimization of hyperparameter perhaps we can tune timing and possibly increase accuracy. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "#iterate through possible parameters to find best combo\n",
    "nmf_param_grid = {\"init\": [\"nndsvdar\", \"nndsvd\"],\n",
    "                  \"solver\": [\"mu\"], #'cd' doesn't work with kullback-leibler\n",
    "                  \"beta_loss\": ['kullback-leibler'],\n",
    "                  \"alpha_W\" : [0, 1.0],\n",
    "                  \"alpha_H\" : [0, 0.5, 1.0],\n",
    "                  \"l1_ratio\" : [0, 0.5, 1.0]}\n",
    "records = {k:list() for k, v in nmf_param_grid.items()}\n",
    "records[\"accuracy\"] = list()\n",
    "max_nmf_acc, best_nmf_clf = 0, None\n",
    "for params in ParameterGrid(nmf_param_grid):\n",
    "    clf = NMF(n_components=5, max_iter=1000, **params).fit(tfv_train, y_train)\n",
    "    for k, v in params.items():\n",
    "        records[k].append(v)\n",
    "    y_train_pred = predict(clf.transform(tfv_train))\n",
    "    label_order, acc =  label_permute_compare(BBC_train,y_train_pred)\n",
    "    #acc = np.mean(y_train==y_train_pred)\n",
    "    records[\"accuracy\"].append(acc)\n",
    "    if (acc > max_nmf_acc):\n",
    "        max_nmf_acc, best_nmf_clf = acc, clf\n",
    "\n",
    "print( \"best model:\" , best_nmf_clf, \"\\n accuracy\",round(max_nmf_acc *100,2),'%')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "best model: NMF(alpha_H=0, alpha_W=1.0, beta_loss='kullback-leibler', init='nndsvdar',\n",
      "    l1_ratio=0, max_iter=1000, n_components=5, solver='mu') \n",
      " accuracy 94.12 %\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "#for informational purposes, a table displaying parameters tested and accuracy rating\n",
    "display(pd.DataFrame(records))"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "        init solver         beta_loss  alpha_W  alpha_H  l1_ratio  accuracy\n",
       "0   nndsvdar     mu  kullback-leibler      0.0      0.0       0.0  0.938472\n",
       "1   nndsvdar     mu  kullback-leibler      0.0      0.0       0.5  0.939148\n",
       "2   nndsvdar     mu  kullback-leibler      0.0      0.0       1.0  0.938472\n",
       "3     nndsvd     mu  kullback-leibler      0.0      0.0       0.0  0.926978\n",
       "4     nndsvd     mu  kullback-leibler      0.0      0.0       0.5  0.926978\n",
       "5     nndsvd     mu  kullback-leibler      0.0      0.0       1.0  0.926978\n",
       "6   nndsvdar     mu  kullback-leibler      1.0      0.0       0.0  0.941176\n",
       "7   nndsvdar     mu  kullback-leibler      1.0      0.0       0.5  0.926978\n",
       "8   nndsvdar     mu  kullback-leibler      1.0      0.0       1.0  0.926302\n",
       "9     nndsvd     mu  kullback-leibler      1.0      0.0       0.0  0.926978\n",
       "10    nndsvd     mu  kullback-leibler      1.0      0.0       0.5  0.908722\n",
       "11    nndsvd     mu  kullback-leibler      1.0      0.0       1.0  0.908722\n",
       "12  nndsvdar     mu  kullback-leibler      0.0      0.5       0.0  0.938472\n",
       "13  nndsvdar     mu  kullback-leibler      0.0      0.5       0.5  0.939824\n",
       "14  nndsvdar     mu  kullback-leibler      0.0      0.5       1.0  0.939148\n",
       "15    nndsvd     mu  kullback-leibler      0.0      0.5       0.0  0.926978\n",
       "16    nndsvd     mu  kullback-leibler      0.0      0.5       0.5  0.930358\n",
       "17    nndsvd     mu  kullback-leibler      0.0      0.5       1.0  0.932387\n",
       "18  nndsvdar     mu  kullback-leibler      1.0      0.5       0.0  0.748479\n",
       "19  nndsvdar     mu  kullback-leibler      1.0      0.5       0.5  0.232590\n",
       "20  nndsvdar     mu  kullback-leibler      1.0      0.5       1.0  0.232590\n",
       "21    nndsvd     mu  kullback-leibler      1.0      0.5       0.0  0.615957\n",
       "22    nndsvd     mu  kullback-leibler      1.0      0.5       0.5  0.232590\n",
       "23    nndsvd     mu  kullback-leibler      1.0      0.5       1.0  0.232590\n",
       "24  nndsvdar     mu  kullback-leibler      0.0      1.0       0.0  0.937796\n",
       "25  nndsvdar     mu  kullback-leibler      0.0      1.0       0.5  0.939824\n",
       "26  nndsvdar     mu  kullback-leibler      0.0      1.0       1.0  0.939824\n",
       "27    nndsvd     mu  kullback-leibler      0.0      1.0       0.0  0.927654\n",
       "28    nndsvd     mu  kullback-leibler      0.0      1.0       0.5  0.929006\n",
       "29    nndsvd     mu  kullback-leibler      0.0      1.0       1.0  0.931711\n",
       "30  nndsvdar     mu  kullback-leibler      1.0      1.0       0.0  0.557809\n",
       "31  nndsvdar     mu  kullback-leibler      1.0      1.0       0.5  0.232590\n",
       "32  nndsvdar     mu  kullback-leibler      1.0      1.0       1.0  0.232590\n",
       "33    nndsvd     mu  kullback-leibler      1.0      1.0       0.0  0.444219\n",
       "34    nndsvd     mu  kullback-leibler      1.0      1.0       0.5  0.232590\n",
       "35    nndsvd     mu  kullback-leibler      1.0      1.0       1.0  0.232590"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>init</th>\n",
       "      <th>solver</th>\n",
       "      <th>beta_loss</th>\n",
       "      <th>alpha_W</th>\n",
       "      <th>alpha_H</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nndsvdar</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.938472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nndsvdar</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.939148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nndsvdar</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.938472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nndsvd</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.926978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nndsvd</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.926978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nndsvd</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.926978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nndsvdar</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nndsvdar</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.926978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nndsvdar</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.926302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nndsvd</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.926978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nndsvd</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.908722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nndsvd</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.908722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>nndsvdar</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.938472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nndsvdar</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.939824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nndsvdar</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.939148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>nndsvd</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.926978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nndsvd</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.930358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>nndsvd</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.932387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>nndsvdar</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.748479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nndsvdar</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.232590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>nndsvdar</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.232590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>nndsvd</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.615957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>nndsvd</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.232590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>nndsvd</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.232590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>nndsvdar</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>nndsvdar</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.939824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>nndsvdar</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.939824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>nndsvd</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.927654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>nndsvd</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.929006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>nndsvd</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.931711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>nndsvdar</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.557809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>nndsvdar</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.232590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>nndsvdar</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.232590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>nndsvd</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>nndsvd</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.232590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>nndsvd</td>\n",
       "      <td>mu</td>\n",
       "      <td>kullback-leibler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.232590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "#predict and get label order of best model\n",
    "y_train = predict(best_nmf_clf.transform(tfv_train))\n",
    "label_order, acc =  label_permute_compare(BBC_train,y_train)\n",
    "print('accuracy =', round(acc*100,2),'%', \"\\nlabel_order\", label_order)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy = 94.12 % \n",
      "label_order (4, 2, 1, 0, 3)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the optimization, we were able to improve performance to 94.12% accuracy in 1.4 seconds. Let's take a look at a confusion matrix to break down the assignments."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "#print label assignments\n",
    "label_dict = {}\n",
    "cats = ['business', 'tech', 'politics', 'sport', 'entertainment']\n",
    "for i in range(5):\n",
    "    label_dict[label_order[i]] = cats[i]\n",
    "\n",
    "print(label_dict)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{4: 'business', 2: 'tech', 1: 'politics', 0: 'sport', 3: 'entertainment'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Getting the labels of the categories\n",
    "labels = BBC_train['Category'].unique()\n",
    "y_pred = pd.DataFrame(y_train)\n",
    "\n",
    "# plot confusion matrix\n",
    "cm = confusion_matrix(BBC_train['Category'], y_pred[0].map(label_dict), labels=labels)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Reds',xticklabels=labels, yticklabels=labels)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix for Training Data')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It looks like the highest misclassified article were business articles which were mistake for tech articles. This is actually makes a lot of sense with the state of our economy now and how intertwined business and technology topics often are. In its current state, the model's performance is acceptable to apply to the testing dataset and submit for the competition."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "#prep test dataset\n",
    "#dont clean testing dataset! it will lead to overfitting\n",
    "tfv_test= tfv.transform(BBC_test['Text'])\n",
    "best_nmf_clf.transform(tfv_test)\n",
    "y_test = predict(best_nmf_clf.transform(tfv_test))\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#create new dataframe to submit to competition\n",
    "test_pred = pd.DataFrame(columns = ['ArticleId','Category','y'])\n",
    "test_pred['ArticleId'] = BBC_test['ArticleId']\n",
    "test_pred['y'] = y_test\n",
    "test_pred['Category'] = test_pred['y'].map(label_dict)\n",
    "\n",
    "test_pred= test_pred.drop('y', axis = 1)\n",
    "test_pred.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "try: \n",
    "    test_pred.to_csv('BBCclass_submission.csv', index=False)\n",
    "except: \n",
    "    pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The predicted testing file was uploaded to the kaggle testing competition and yielded an accuracy rating of 96.6% \n",
    " \n",
    " ![picTitle](bbc_test_accuracy.png)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Supervised Learning Model training and building \n",
    "\n",
    "Now we are going to train a supervised learning model and compare performance to the unsupervised learning model. We will still apply the TfidfVectorizer. I've chosen to implement support vector machines."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "BBC_train_SML =pd.read_csv('BBC News Train.csv')\n",
    "BBC_train_SML = cleanup_text(BBC_train_SML, 'Text')\n",
    "tvf_sml = TfidfVectorizer(min_df = 0, max_df = 0.85, norm = 'l2', stop_words = 'english')\n",
    "x = tvf_sml.fit_transform(BBC_train_SML['clean_text'])\n",
    "y = BBC_train_SML['Category']\n",
    "\n",
    "# Split the data into training and testing sets (80/20 split)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=101)\n",
    "\n",
    "# Display the shape of the resulting feature matrices\n",
    "x_train.shape, x_test.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((1192, 25039), (298, 25039))"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "from sklearn import svm\n",
    "\n",
    "\n",
    "train_sizes = [0.1, 0.2, 0.5, 1.0]\n",
    "eval_metrics = {'Training size':[],'Training set accuracy':[], 'Testing set accuracy':[]}\n",
    "\n",
    "for item in train_sizes:\n",
    "    train_size = int(item*x_train.shape[0])\n",
    "\n",
    "    svc = svm.SVC(random_state=101)\n",
    "    svc.fit(x_train[:train_size], y_train[:train_size])\n",
    "    y_train_pred = svc.predict(x_train)\n",
    "    y_test_pred = svc.predict(x_test)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    eval_metrics['Training size'].append(f'{item*100}%')\n",
    "    eval_metrics['Training set accuracy'].append(f\"{train_accuracy:.2%}\")\n",
    "    eval_metrics['Testing set accuracy'].append(f\"{test_accuracy:.2%}\")\n",
    "\n",
    "\n",
    "eval_df = pd.DataFrame(eval_metrics)\n",
    "eval_df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Training size Training set accuracy Testing set accuracy\n",
       "0         10.0%                83.31%               77.85%\n",
       "1         20.0%                94.80%               94.63%\n",
       "2         50.0%                96.98%               94.97%\n",
       "3        100.0%               100.00%               96.31%"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training size</th>\n",
       "      <th>Training set accuracy</th>\n",
       "      <th>Testing set accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0%</td>\n",
       "      <td>83.31%</td>\n",
       "      <td>77.85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0%</td>\n",
       "      <td>94.80%</td>\n",
       "      <td>94.63%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.0%</td>\n",
       "      <td>96.98%</td>\n",
       "      <td>94.97%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0%</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>96.31%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "in this exercise of implementing a support vector machine classifier, only 20% of the training split (which is 80% of the original  data provided with labels) was required for acceptable accuracy.\n",
    "\n",
    "It doesn't look like overfitting is too much of an issue even up to utilization of 100% of the training size. This was likely mitgated well because of the split of training and testing datasets."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's implement the trained model on the actual testing dataset and submit to the competition..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "svc = svm.SVC(random_state=101)\n",
    "# try only 20% and 50% of original 80% of training data\n",
    "train_size = int(0.5*x_train.shape[0])\n",
    "svc.fit(x_train[:train_size], y_train[:train_size])\n",
    "#comment out above 2 lines and uncomment line below to run training on full training dataset.\n",
    "#svc.fit(x, y)\n",
    "\n",
    "tvf_sml_test = tvf_sml.transform(BBC_test['Text'])\n",
    "y_test_sup = svc.predict(tvf_sml_test)\n",
    "\n",
    "#create new dataframe to submit to competition\n",
    "test_pred = pd.DataFrame(columns = ['ArticleId','Category'])\n",
    "test_pred['ArticleId'] = BBC_test['ArticleId']\n",
    "test_pred['Category'] = y_test_sup\n",
    "#test_pred = test_pred['y'].map(label_dict)\n",
    "\n",
    "#test_pred= test_pred.drop('y', axis = 1)\n",
    "test_pred.head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   ArticleId       Category\n",
       "0       1018          sport\n",
       "1       1319           tech\n",
       "2       1138          sport\n",
       "3        459       business\n",
       "4       1020          sport\n",
       "5         51          sport\n",
       "6       2025       politics\n",
       "7       1479       politics\n",
       "8         27  entertainment\n",
       "9        397       business"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1018</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1319</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1138</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1479</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>397</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "try: \n",
    "    test_pred.to_csv('BBCclass_submission_sup.csv', index=False)\n",
    "except: \n",
    "    pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "With 100% of the training data utilized, I was able to get an accuracy rating of 98.2% which is highly accurate! With a reduction of the training data to 50% and 20%, I was still able to get an accuracy rating of 96% and 93.7% which is higher than the and similar to unsupervised model utilizing the full training dataset. Given this performance comparison, the supervised learning method was superior in terms of data efficiency.\n",
    "\n",
    "20% of training data \n",
    " ![20% of training data](bbc_sup_20.png)\n",
    "\n",
    " 50% of training data\n",
    "  ![50% of training data](bbc_sup_50.png)\n",
    "\n",
    "100% of training data\n",
    " ![100% of training data](bbc_sup_100.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Limitation(s) of sklearn’s non-negative matrix factorization library."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we will take a chance to explore the limitations of sklearn's non-negative matrix factorization library by implementing a NMF model on the movie ratings data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "#load in data\n",
    "MV_users = pd.read_csv('users.csv')\n",
    "MV_movies = pd.read_csv('movies.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "#preview dataframes\n",
    "dfs = {\"users\":MV_users, \"movies\":MV_movies,\"Training\": train,\"Testing\": test}\n",
    "\n",
    "for title, df in dfs.items():\n",
    "    print(\"preview of\", title)\n",
    "    display(df.head())\n",
    "    print(\"\\n\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "preview of users\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "   uID gender  age  accupation    zip\n",
       "0    1      F    1          10  48067\n",
       "1    2      M   56          16  70072\n",
       "2    3      M   25          15  55117\n",
       "3    4      M   45           7  02460\n",
       "4    5      M   25          20  55455"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uID</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>accupation</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "preview of movies\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "   mID                        title  year  Doc  Com  Hor  Adv  Wes  Dra  Ani  \\\n",
       "0    1                    Toy Story  1995    0    1    0    0    0    0    1   \n",
       "1    2                      Jumanji  1995    0    0    0    1    0    0    0   \n",
       "2    3             Grumpier Old Men  1995    0    1    0    0    0    0    0   \n",
       "3    4            Waiting to Exhale  1995    0    1    0    0    0    1    0   \n",
       "4    5  Father of the Bride Part II  1995    0    1    0    0    0    0    0   \n",
       "\n",
       "   ...  Chi  Cri  Thr  Sci  Mys  Rom  Fil  Fan  Act  Mus  \n",
       "0  ...    1    0    0    0    0    0    0    0    0    0  \n",
       "1  ...    1    0    0    0    0    0    0    1    0    0  \n",
       "2  ...    0    0    0    0    0    1    0    0    0    0  \n",
       "3  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "4  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mID</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>Doc</th>\n",
       "      <th>Com</th>\n",
       "      <th>Hor</th>\n",
       "      <th>Adv</th>\n",
       "      <th>Wes</th>\n",
       "      <th>Dra</th>\n",
       "      <th>Ani</th>\n",
       "      <th>...</th>\n",
       "      <th>Chi</th>\n",
       "      <th>Cri</th>\n",
       "      <th>Thr</th>\n",
       "      <th>Sci</th>\n",
       "      <th>Mys</th>\n",
       "      <th>Rom</th>\n",
       "      <th>Fil</th>\n",
       "      <th>Fan</th>\n",
       "      <th>Act</th>\n",
       "      <th>Mus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "preview of Training\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "    uID   mID  rating\n",
       "0   744  1210       5\n",
       "1  3040  1584       4\n",
       "2  1451  1293       5\n",
       "3  5455  3176       2\n",
       "4  2507  3074       5"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uID</th>\n",
       "      <th>mID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>744</td>\n",
       "      <td>1210</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3040</td>\n",
       "      <td>1584</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1451</td>\n",
       "      <td>1293</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5455</td>\n",
       "      <td>3176</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2507</td>\n",
       "      <td>3074</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "preview of Testing\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "    uID   mID  rating\n",
       "0  2233   440       4\n",
       "1  4274   587       5\n",
       "2  2498   454       3\n",
       "3  2868  2336       5\n",
       "4  1636  2686       5"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uID</th>\n",
       "      <th>mID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2233</td>\n",
       "      <td>440</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4274</td>\n",
       "      <td>587</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2498</td>\n",
       "      <td>454</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2868</td>\n",
       "      <td>2336</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1636</td>\n",
       "      <td>2686</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "# Finding the unique number of users and movies\n",
    "unique_users = train['uID'].unique()\n",
    "unique_movies = train['mID'].unique()\n",
    "\n",
    "# Creating a new mapping from original user and movie IDs to connect to testing dataset\n",
    "user_id_mapping = {uid: i for i, uid in enumerate(unique_users)}\n",
    "#dict(enumerate(unique_users))\n",
    "movie_id_mapping = {mid: i for i, mid in enumerate(unique_movies)}\n",
    "#dict(enumerate(unique_movies))\n",
    "\n",
    "\n",
    "# apply mapping to training and testing datasets\n",
    "train['uID'] = train['uID'].apply(lambda uID: user_id_mapping[uID])\n",
    "train['mID'] = train['mID'].apply(lambda mID: movie_id_mapping[mID])\n",
    "test['uID'] = test['uID'].apply(lambda uID: user_id_mapping.get(uID))\n",
    "test['mID'] = test['mID'].apply(lambda mID: movie_id_mapping.get(mID))\n",
    "\n",
    "#create matrix the size of # of users by # of movies\n",
    "rating_matrix = np.zeros((len(unique_users), len(unique_movies)))\n",
    "for index, row in train.iterrows():\n",
    "    rating_matrix[row['uID'], row['mID']] = row['rating']\n",
    "\n",
    "pd.DataFrame(rating_matrix).iloc[:10, :10]\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9\n",
       "0  5.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  0.0\n",
       "1  0.0  4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "2  4.0  0.0  5.0  4.0  0.0  0.0  0.0  0.0  3.0  0.0\n",
       "3  0.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "4  3.0  3.0  0.0  3.0  5.0  0.0  0.0  4.0  4.0  0.0\n",
       "5  5.0  0.0  0.0  0.0  3.0  0.0  0.0  0.0  0.0  1.0\n",
       "6  0.0  3.0  0.0  0.0  0.0  4.0  0.0  4.0  5.0  0.0\n",
       "7  5.0  4.0  0.0  4.0  0.0  0.0  2.0  5.0  0.0  4.0\n",
       "8  0.0  0.0  0.0  0.0  0.0  0.0  0.0  5.0  0.0  0.0\n",
       "9  0.0  2.0  0.0  0.0  5.0  0.0  0.0  3.0  3.0  0.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "#train NMF (non-negative matrix factorization)\n",
    "feats = MV_movies.shape[1]-1\n",
    "mov_nmf = NMF(n_components = feats, random_state= 101)\n",
    "W = mov_nmf.fit_transform(rating_matrix)\n",
    "H = mov_nmf.components_\n",
    "\n",
    "#get predicted rating matrix\n",
    "pred_rating_matrix = np.dot(W,H)\n",
    "pd.DataFrame(pred_rating_matrix).iloc[:10, :10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  4.414168  2.296680  0.264531  0.287094  0.316348  0.087709  0.271297   \n",
       "1  0.590369  0.702372  0.043102  0.086480  0.000000  0.000000  0.000006   \n",
       "2  3.591175  2.782772  2.705911  1.962264  1.292460  0.880703  0.299018   \n",
       "3  2.882501  0.995809  0.264432  1.618092  0.000000  0.360811  0.052516   \n",
       "4  2.200645  2.063167  1.899319  2.429974  0.746378  1.316971  0.093445   \n",
       "5  3.310619  1.695576  3.194894  0.920318  1.430493  0.540691  0.222438   \n",
       "6  1.024102  1.868404  0.331835  1.895384  0.000000  0.338657  0.580726   \n",
       "7  1.650179  0.676401  1.309072  1.549393  0.307462  0.758830  0.212708   \n",
       "8  3.169611  0.969887  0.300799  1.422684  0.211789  0.123433  0.383786   \n",
       "9  1.024160  1.343574  1.246488  1.792947  0.422396  0.473077  0.527418   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.446441  0.321749  0.306868  \n",
       "1  0.109248  0.005679  0.006859  \n",
       "2  2.003230  1.107973  0.465519  \n",
       "3  0.206151  1.203198  0.028518  \n",
       "4  2.518317  1.801557  0.442708  \n",
       "5  0.351835  0.114389  0.133881  \n",
       "6  1.532863  1.567012  1.352864  \n",
       "7  1.769011  1.432793  0.933992  \n",
       "8  1.919201  1.428500  0.243504  \n",
       "9  1.899663  1.742034  0.935446  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.414168</td>\n",
       "      <td>2.296680</td>\n",
       "      <td>0.264531</td>\n",
       "      <td>0.287094</td>\n",
       "      <td>0.316348</td>\n",
       "      <td>0.087709</td>\n",
       "      <td>0.271297</td>\n",
       "      <td>0.446441</td>\n",
       "      <td>0.321749</td>\n",
       "      <td>0.306868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.590369</td>\n",
       "      <td>0.702372</td>\n",
       "      <td>0.043102</td>\n",
       "      <td>0.086480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.109248</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.006859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.591175</td>\n",
       "      <td>2.782772</td>\n",
       "      <td>2.705911</td>\n",
       "      <td>1.962264</td>\n",
       "      <td>1.292460</td>\n",
       "      <td>0.880703</td>\n",
       "      <td>0.299018</td>\n",
       "      <td>2.003230</td>\n",
       "      <td>1.107973</td>\n",
       "      <td>0.465519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.882501</td>\n",
       "      <td>0.995809</td>\n",
       "      <td>0.264432</td>\n",
       "      <td>1.618092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.360811</td>\n",
       "      <td>0.052516</td>\n",
       "      <td>0.206151</td>\n",
       "      <td>1.203198</td>\n",
       "      <td>0.028518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.200645</td>\n",
       "      <td>2.063167</td>\n",
       "      <td>1.899319</td>\n",
       "      <td>2.429974</td>\n",
       "      <td>0.746378</td>\n",
       "      <td>1.316971</td>\n",
       "      <td>0.093445</td>\n",
       "      <td>2.518317</td>\n",
       "      <td>1.801557</td>\n",
       "      <td>0.442708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.310619</td>\n",
       "      <td>1.695576</td>\n",
       "      <td>3.194894</td>\n",
       "      <td>0.920318</td>\n",
       "      <td>1.430493</td>\n",
       "      <td>0.540691</td>\n",
       "      <td>0.222438</td>\n",
       "      <td>0.351835</td>\n",
       "      <td>0.114389</td>\n",
       "      <td>0.133881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.024102</td>\n",
       "      <td>1.868404</td>\n",
       "      <td>0.331835</td>\n",
       "      <td>1.895384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338657</td>\n",
       "      <td>0.580726</td>\n",
       "      <td>1.532863</td>\n",
       "      <td>1.567012</td>\n",
       "      <td>1.352864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.650179</td>\n",
       "      <td>0.676401</td>\n",
       "      <td>1.309072</td>\n",
       "      <td>1.549393</td>\n",
       "      <td>0.307462</td>\n",
       "      <td>0.758830</td>\n",
       "      <td>0.212708</td>\n",
       "      <td>1.769011</td>\n",
       "      <td>1.432793</td>\n",
       "      <td>0.933992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.169611</td>\n",
       "      <td>0.969887</td>\n",
       "      <td>0.300799</td>\n",
       "      <td>1.422684</td>\n",
       "      <td>0.211789</td>\n",
       "      <td>0.123433</td>\n",
       "      <td>0.383786</td>\n",
       "      <td>1.919201</td>\n",
       "      <td>1.428500</td>\n",
       "      <td>0.243504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.024160</td>\n",
       "      <td>1.343574</td>\n",
       "      <td>1.246488</td>\n",
       "      <td>1.792947</td>\n",
       "      <td>0.422396</td>\n",
       "      <td>0.473077</td>\n",
       "      <td>0.527418</td>\n",
       "      <td>1.899663</td>\n",
       "      <td>1.742034</td>\n",
       "      <td>0.935446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "y_true = test['rating'].values\n",
    "\n",
    "def get_predicted_rating(uID, mID, predicted_ratings_matrix):\n",
    "    if not np.isnan(uID) and not np.isnan(mID):\n",
    "        return predicted_ratings_matrix[int(uID), int(mID)]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "y_pred = test.apply(lambda row: get_predicted_rating(row['uID'], row['mID'], pred_rating_matrix), axis=1)\n",
    "\n",
    "# Calculate the RMSE\n",
    "rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "round(rmse,4)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.8609"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The root mean square error (RMSE) for the predictions on the test set is approximately 2.8609. This value represents the average of the differences between the true ratings and the predicted ratings; a lower value would indicate more accurate predictions. This value is well over the typical acceptable range of 0.2-0.5 and therefore indicates this model does not perform well. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The utilization of the non-negative matrix factorization library didn't work as well compared to simple baseline or similarity-based methods as practiced in week 3. Some of these reasons could include that similarity-based methods can help give Eigen vectors of the input matrix. This intermidiary matrix can give insights into the amount of information each eigen vector holds and provide better modeling of training data. These methods are deterministic and can allow for more predictable model behavior \n",
    "\n",
    "NMF splits a given matrix into the product of two matrices. It tries to get best fit decomposed matrices, which are trained on some training data and then done an evaluation on test data. It does not do very well in filling in missing values This method is more stochastic and allows for more randomness to makes its way to into the modeling. There may be opportunities to decrease the RMSE by tuning hyperparameters or trying out different initialization parameters. Another option would be to implement an NMF algorithim with improved population of missing values, since arbitrary assignment "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## References\n",
    "1. Scikit-Learn Library Documentation\n",
    "- [Scikit-Learn User Guide for NMF](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html)\n",
    "- [Scikit-Learn 1.4 Support Vector Machines](https://scikit-learn.org/stable/modules/svm.html#svm)\n",
    "- [Scikit-Learn Method Documentation for TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer)\n",
    "- [Scikit-Learn Method Documentation for CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer)\n",
    "- [Scikit-Learn User Guide for Feature Extractio](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)\n",
    "2. Online Resources and Tutorials\n",
    "Medium Articles, Stack Overflow threads, Kaggle, github, and various other online resources for implementing NMF.\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "344443636c3027c5042750c9c609acdda283a9c43681b128a8c1053e7ad2aa7d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}